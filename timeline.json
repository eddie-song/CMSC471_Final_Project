{
  "title": {
    "text": {
      "headline": "AI Through the Ages",
      "text": "Group 20: Senthoor Krishnaraju, Edward Song, Pranav Hedge"
    },
    "background": {
      "url": "https://media.istockphoto.com/id/1470617656/vector/ai-artificial-intelligence-chipset-on-circuit-board-in-futuristic-concept-suitable-for.jpg?s=612x612&w=0&k=20&c=_wC-pphyNI2muaUHG4N9JuYXxJEMDuzx56Dvzr8ZDUk="
    }
  },
  "events": [
    {
      "milestone_name": "Theseus",
      "start_date": {
        "year": "1950"
      },
      "text": {
        "headline": "Theseus the Maze-solving Mouse",
        "text": "Theseus, developed by Claude Shannon in 1950, was an electromechanical mouse capable of navigating a maze, demonstrating early concepts of machine learning. The system used a magnetic sensor to detect paths and learned from mistakes, showcasing one of the first implementations of adaptive behavior in artificial intelligence."
      },
      "media": {
        "url": "https://upload.wikimedia.org/wikipedia/commons/7/70/Theseus_Maze_by_Claude_Shannon%2C_1952_-_MIT_Museum_-_DSC03702.JPG",
        "caption": "Claude Shannon's Theseus, a foundational experiment in AI."
      },
      "background": {
        "url": "https://img.freepik.com/free-vector/classic-vintage-rays-sunburst-retro-background_1017-33769.jpg?semt=ais_hybrid&w=740"
      }
    },
    {
      "milestone_name": "Perceptron Mark I",
      "start_date": {
        "year": "1957"
      },
      "text": {
        "headline": "Perceptron Mark I",
        "text": "Frank Rosenblatt developed the Perceptron, one of the earliest models of an artificial neural network. Designed for pattern recognition, it marked a foundational moment in AI by demonstrating how machines could learn from data through iterative adjustments. The Perceptron laid the groundwork for modern deep learning techniques."
      },
      "media": {
        "url": "https://news.cornell.edu/sites/default/files/styles/full_size/public/2019-09/0925_rosenblatt5.jpg?itok=7UpHtbRj",
        "caption": "Frank Rosenblatt adjusting the Perceptron."
      },
      "background": {
        "url": "https://anatomiesofintelligence.github.io/img/p/perceptron-markI-diagram.png"
      }
    },
    {
      "milestone_type": "compute",
      "milestone_name": "IBM 7030 Stretch",
      "start_date": {
        "year": "1961"
      },
      "text": {
        "headline": "IBM's First Supercomputer: IBM 7030 Stretch",
        "text": "The IBM 7030 Stretch was the world's fastest computer at the time, achieving groundbreaking performance for scientific computing. Though initially deemed a commercial failure, it introduced advanced architectural concepts like instruction pipelining and memory interleaving, which later became standard in modern computing."
      },
      "media": {
        "url": "https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/arc/cf/ul/g/d4/fc/16834_stretch8.jpg/_jcr_content/renditions/cq5dam.medium.1584.1584.jpeg",
        "caption": ""
      },
      "background": {
        "url": "https://wallpapercat.com/w/full/3/7/5/2113037-2560x1440-desktop-hd-ibm-background-photo.jpg"
      }
    },
    {
      "milestone_name": "ELIZA",
      "start_date": {
        "year": "1966"
      },
      "text": {
        "headline": "The First Chatbot: ELIZA",
        "text": "Developed by Joseph Weizenbaum at MIT, ELIZA was one of the first chatbots, designed to simulate conversation using pattern matching and scripted responses. ELIZA's most famous script, DOCTOR, mimicked a Rogerian psychotherapist, leading many users to believe they were conversing with a real human."
      },
      "media": {
        "url": "https://upload.wikimedia.org/wikipedia/commons/7/79/ELIZA_conversation.png",
        "caption": "ELIZA, a pioneering chatbot demonstrating natural language processing."
      },
      "background": {
        "color": "#232729"
      }
    },
    {
      "milestone_name": "Neocognitron",
      "start_date": {
        "year": "1980"
      },
      "text": {
        "headline": "Neocognitron: Japanese Handwriting Recognition",
        "text": "The Neocognitron, developed by Japanese computer scientist Kunihiko Fukushima, was a pioneering neural network model designed for visual pattern recognition. It introduced hierarchical layers to process visual information and was particularly successful in recognizing handwritten Japanese characters. This innovation laid the groundwork for modern convolutional neural networks used in image and text analysis."
      },
      "media": {
        "url": "https://miro.medium.com/v2/resize:fit:1400/0*qq8NM5pgElCjVJBK.png",
        "caption": "Diagram showcasing the architecture of the Neocognitron"
      }
    },
    {
      "milestone_name": "Cray X-MP",
      "milestone_type": "compute",
      "start_date": {
        "year": "1983"
      },
      "text": {
        "headline": "Cray X-MP: Breaking the 1 GFLOP Barrier",
        "text": "  The Cray X-MP, introduced in 1982, was the first supercomputer to break the 1 GFLOP/s barrier (one billion floating-point operations per second). This achievement marked a major milestone in computing power, demonstrating the rapid advancements in hardware that would continue to shape AI and data processing technologies."
      },
      "media": {
        "url": "https://images.fineartamerica.com/images-medium-large-5/cray-x-mp48-supercomputer-jerry-masonscience-photo-library.jpg",
        "caption": "The processor of the Cray X-MP supercomputer, installed at the Atlas Centre of the Rutherford Appleton Laboratory, Oxfordshire, U.K"
      }, 
      "background": {
        "color": "black"
      }
    },
    {
      "milestone_name": "Back-propagation",
      "start_date": {
        "year": "1986"
      },
      "text": {
        "headline": "Back Propagation",
        "text": "Popularized by the 1986 white paper by Rumelhart, Hinton, and Williams, backpropagation became a fundamental algorithm for training artificial neural networks that took the concept of the Perceptron to the next level. By efficiently calculating gradients, it enabled multi-layer networks to learn from data, paving the way for modern deep learning techniques."
      },
      "media": {
        "url": "https://miro.medium.com/v2/resize:fit:1080/0*d9yJ5xIqdbDyjCYR.gif",
        "caption": "Animation showcasing the flow of data during backpropagation in a neural network"
      },
      "background": {
        "color": "black"
      }
    },
    {
      "milestone_name": "TD-Gammon",
      "start_date": {
        "year": "1992"
      },
      "text": {
        "headline": "TD-Gammon",
        "text": "Developed by IBM researcher Gerald Tesauro, TD-Gammon was the first AI to achieve expert-level play in backgammon using reinforcement learning and self-play, without being programmed with human strategies. It marked the start of modern machine learning being applied to games, paving the way for later breakthroughs like AlphaGo."
      },
      "media": {
        "url": "https://achievements.ai/wp-content/uploads/2021/01/td-gammon-program-developed-by-gerald-tesauro-1.jpg",
        "caption": "TD-Gammon, one of the first successful uses of reinforcement learning applied to games."
      },
      "background": {
        "url": "https://media.istockphoto.com/id/170618222/photo/backgammon-board-background.jpg?s=612x612&w=0&k=20&c=zVquSTv7Ch4UzSJzGrhA09FfNh2hLNIKkq4fQrvZcxo="
      }
    },
    {
      "milestone_name": "Support Vector Machines",
      "start_date": {
        "year": "1995"
      },
      "text": {
        "headline": "Support Vector Machines",
        "text": "Introduced as a powerful method for classification, SVMs use geometry to find the optimal boundary between classes. They became a key tool in early machine learning, widely used in text classification, image recognition, and bioinformatics before the deep learning era."
      },
      "media": {
        "url": "https://miro.medium.com/max/333/0*aiT6AJL16jgGmjh_.gif",
        "caption": "Animation showcasing the Support Vector Machine algorithm"
      },
      "background": {
        "color": "black"
      }
    },
    {
      "milestone_type": "compute",
      "milestone_name": "NASA Beowulf Cluster",
      "start_date": {
        "year": "1994"
      },
      "text": {
        "headline": "NASA's Beowulf Cluster",
        "text": "NASA develops the Beowulf cluster, a low-cost supercomputing architecture built from off-the-shelf PCs. It revolutionized high-performance computing by making parallel processing more accessible, laying the groundwork for modern compute infrastructure used in AI research today."
      },
      "media": {
        "url": "https://www.spacefoundation.org/wp-content/uploads/2022/08/Beowolf2.jpg",
        "caption": "Beowulf Cluster installment at the NASA Goddard Space Flight Center"
      },
      "background": {
        "url": "https://i.ytimg.com/vi/p4YdZiTMPUc/hq720.jpg?sqp=-oaymwE7CK4FEIIDSFryq4qpAy0IARUAAAAAGAElAADIQj0AgKJD8AEB-AH-CYAC0AWKAgwIABABGBMgMCh_MA8=&rs=AOn4CLDld2kLIKyvd74GudtuEUaL_wDJxA"
      }
    },
    {
      "milestone_name": "Deep Blue",
      "start_date": {
        "year": "1997"
      },
      "text": {
        "headline": "Deep Blue Defeats Kasparov",
        "text": "IBM's Deep Blue becomes the first computer to defeat reigning world chess champion Garry Kasparov in a match. This landmark victory showcased the power of brute-force search and specialized hardware in AI, capturing global attention."
      },
      "media": {
        "url": "https://cdn.theatlantic.com/media/mt/science/kasparov615.jpg",
        "caption": "Deep Blue's victory marked a milestone in game-playing AI."
      },
      "background": {
        "url": "https://png.pngtree.com/thumb_back/fh260/background/20230610/pngtree-black-and-white-chess-pieces-in-a-hall-image_2918699.jpg"
      }
    },
    {
      "milestone_name": "LeNet-5",
      "start_date": {
        "year": "1998"
      },
      "text": {
        "headline": "LeNet-5",
        "text": " LeNet-5 was a breakthrough AI model that taught computers to recognize handwritten digits with impressive accuracy. By automatically learning important features from images, it improved the way machines understand visual information and helped pave the way for more advanced AI in image recognition."
      },
      "media": {
        "url": "https://vitalab.github.io/article/images/lenet/a384.gif",
        "caption": "A LeNet-5 Demo on a batch of handwritten digits"
      },
      "background": {
        "color": "#399ABB"
      }
    },
    {
      "milestone_name": "Hiero",
      "start_date": {
        "year": "2005"
      },
      "text": {
        "headline": "Hiero: UMD's Machine Translation System",
        "text": "Developed by researchers from the University of Maryland, Hiero is a statistical machine translation system that takes advatange of the hierarchical nature of lanaguage by using the unique approach of hierarchical phrase-based models to improve translation accuracy.  "
      },
      "background": {
        "url": "https://wallpapers.com/images/hd/university-of-maryland-terrapin-shell-nefppid5p07m9nl3.jpg"
      }
    },
    {
      "milestone_type": "compute",
      "milestone_name": "NVIDIA GeForce GTX 280",
      "start_date": {
        "year": "2008"
      },
      "text": {
        "headline": "NVIDIA and CUDA: The GPU Computing Revolution",
        "text": "NVIDIA released CUDA (Compute Unified Device Architecture) which revolutionized parallel computing by enabling GPUs to perform general-purpose processing. Alongside CUDA, new lines of NVIDIA GPUs - like the GTX 280 - marked a drastic leap in performance, making GPU-accelerated computing accessible for scientific simulations, AI research, and high-performance applications."
      },
      "media": {
        "url": "https://tpucdn.com/gpu-specs/images/b/2251-front.small.jpg",
        "caption": "The NVIDIA GeForce GTX 280, a large improvement in compute cost"
      },
      "background": {
        "url": "https://wallpapercat.com/w/full/9/7/c/1255566-3840x2160-desktop-4k-nvidia-background-photo.jpg"
      }
    },
    {
      "milestone_name": "AlexNet",
      "start_date": {
        "year": "2012"
      },
      "text": {
        "headline": "AlexNet Wins ImageNet",
        "text": "AlexNet, a deep convolutional neural network, wins the ImageNet competition by a large margin, demonstrating the power of deep learning. Creators of AlexNet attributed a large part of their success in their use of parallel Nvidia GPUs to boost the computational power of their neural network."
      },
      "media": {
        "url": "https://miro.medium.com/v2/resize:fit:1400/0*xFY-719luaVR1wjY.png",
        "caption": "AlexNet's success popularized deep learning techniques."
      }
    },
    {
      "milestone_name": "AlphaGo Lee",
      "start_date": {
        "year": "2016"
      },
      "text": {
        "headline": "AlphaGo Defeats Lee Sedol",
        "text": "DeepMind's AlphaGo defeats world Go champion Lee Sedol, demonstrating the potential of deep reinforcement learning."
      },
      "media": {
        "url": "https://i.redd.it/zmwmm6lx05cb1.jpg",
        "caption": "AlphaGo marked a significant advance in AI game playing."
      }
    },
    {
      "milestone_type": "compute",
      "milestone_name": "NVIDIA Tesla V100",
      "start_date": {
        "year": "2017"
      },
      "text": {
        "headline": "NVIDIA Tesla V100 & Tensor Cores",
        "text": "The Tesla V100 introduced Tensor Cores - specialized hardware units designed to accelerate matrix multiplication and accumulate operations, which is extremely useful for Machine Learning. It's the world's first GPU to break the 100 teraflops (TFLOPS) barrier of deep learning performance, delivering massive improvements in training and inference speed for AI models and making it a cornerstone in data centers, cloud platforms, and research institutions."
      },
      "media": {
        "url": "https://images.contentstack.io/v3/assets/blt71da4c740e00faaa/blt20563cbe49c355d2/5eea631c5f3aa42c4669df22/V100-Specs.jpg",
        "caption": ""
      },
      "background": {
        "color": "black"
      }
    },
    {
      "milestone_name": "BERT-Large",
      "start_date": {
        "year": "2018"
      },
      "text": {
        "headline": "BERT: Breakthrough in NLP",
        "text": "Google's BERT model significantly improves natural language understanding tasks, establishing a new standard for NLP benchmarks."
      },
      "media": {
        "url": "https://miro.medium.com/v2/resize:fit:1200/0*ZenLUXS5ubzvc9lB.png",
        "caption": "BERT demonstrated the potential of transformer models in NLP."
      }
    },
    {
      "milestone_name": "GPT-2 (1.5B)",
      "start_date": {
        "year": "2019"
      },
      "text": {
        "headline": "GPT-2 Released",
        "text": "OpenAI releases GPT-2, demonstrating coherent and versatile natural language generation with 1.5 billion parameters."
      },
      "media": {
        "url": "https://miro.medium.com/v2/resize:fit:2800/1*pitt26-yeiJlxaWS4G2-_w.jpeg",
        "caption": "GPT-2 significantly advanced natural language generation."
      }
    },
    {
      "milestone_name": "AlphaFold",
      "start_date": {
        "year": "2020"
      },
      "text": {
        "headline": "AlphaFold Solves Protein Folding",
        "text": "DeepMind's AlphaFold predicts protein structures with unprecedented accuracy, solving a decades-old biological problem."
      },
      "media": {
        "url": "https://cen.acs.org/content/dam/cen/99/28/WEB/09928-leadcon-protein.jpg",
        "caption": "AlphaFold's breakthrough in structural biology."
      }
    },
    {
      "milestone_name": "GPT-4",
      "start_date": {
        "year": "2023"
      },
      "text": {
        "headline": "GPT-4 Released",
        "text": "OpenAI's GPT-4 pushes language generation boundaries, enabling complex text generation and reasoning capabilities."
      },
      "media": {
        "url": "https://upload.wikimedia.org/wikipedia/commons/0/04/ChatGPT_logo.svg",
        "caption": "GPT-4, a leading LLM for natural language tasks."
      }
    }
  ]
}